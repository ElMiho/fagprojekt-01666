{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d4e637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b88571",
   "metadata": {},
   "source": [
    "# Convert Between Formats\n",
    "Using the shunting yard algo: https://brilliant.org/wiki/shunting-yard-algorithm/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd7e02c",
   "metadata": {},
   "source": [
    "### Tokenize equation variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff175126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token class\n",
    "class Token:\n",
    "    def __init__(self, t_type, t_value=None):\n",
    "        self.t_type = t_type\n",
    "        self.t_value = t_value\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"---- Type: {self.t_type} \\t Value: {self.t_value} ----\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d059874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokens\n",
    "## Variable\n",
    "TT_VARIABLE = \"TT_VARIABLE\"\n",
    "\n",
    "## Specials\n",
    "TT_LEFT_PARENTHESIS = \"TT_LEFT_PARENTHESIS\"\n",
    "TT_RIGHT_PARENTHESIS = \"TT_RIGHT_PARENTHESIS\"\n",
    "\n",
    "## Special numbers\n",
    "TT_PI = \"TT_PI\"\n",
    "TT_E = \"TT_E\"\n",
    "TT_PHI = \"TT_PHI\"\n",
    "TT_CATALAN = \"TT_CATALAN\"\n",
    "\n",
    "## Numbers\n",
    "TT_INTEGER = \"TT_INTEGER\"\n",
    "TT_RATIONAL = \"TT_RATIONAL\"\n",
    "\n",
    "## Unary Operations\n",
    "TT_SQRT = \"TT_SQRT\"\n",
    "TT_SIN = \"TT_SIN\"\n",
    "TT_COS = \"TT_COS\"\n",
    "TT_TAN = \"TT_TAN\"\n",
    "\n",
    "TT_FACTORIAL = \"TT_FACTORIAL\"\n",
    "\n",
    "## Binary Operations\n",
    "TT_PLUS = \"TT_PLUS\"\n",
    "TT_MINUS = \"TT_MINUS\"\n",
    "TT_MULTIPLY = \"TT_MULTIPLY\"\n",
    "TT_DIVIDE = \"TT_DIVIDE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38c5884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper globals\n",
    "DIGITS = \"0123456789\"\n",
    "ALPHABET = \"ABCDEFGHIJKLMNOPQRSTUVXYZabcdefghijklmnopqrstuvxyz\"\n",
    "\n",
    "SPECIAL_NUMBERS_DICT = {\n",
    "    \"pi\": Token(TT_PI),\n",
    "    \"e\": Token(TT_E),\n",
    "    \"phi\": Token(TT_PHI),\n",
    "    \"G\": Token(TT_CATALAN)\n",
    "}\n",
    "\n",
    "UNI_OPERATORS = {\n",
    "    \"sqrt\": Token(TT_SQRT),\n",
    "    \"sin\": Token(TT_SIN),\n",
    "    \"cos\": Token(TT_COS),\n",
    "    \"tan\": Token(TT_TAN)\n",
    "}\n",
    "BIN_OPERATORS = {\n",
    "    TT_PLUS: \"+\",\n",
    "    TT_MINUS: \"-\",\n",
    "    TT_MULTIPLY: \"*\",\n",
    "    TT_DIVIDE: \"/\",\n",
    "}\n",
    "\n",
    "\n",
    "OPERATOR_PRECEDENCE = {\n",
    "    token.t_type: 0 for token in UNI_OPERATORS.values()\n",
    "}\n",
    "OPERATOR_PRECEDENCE.update({\n",
    "    TT_PLUS: 1,\n",
    "    TT_MINUS: 1,\n",
    "    TT_MULTIPLY: 2,\n",
    "    TT_DIVIDE: 2\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4498bb05",
   "metadata": {},
   "source": [
    "### Lexer implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc6506e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EquationLexer:\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        self.position = -1\n",
    "        self.text_length = len(text)\n",
    "        self.current_char = None\n",
    "        self.advance()\n",
    "    \n",
    "    ###########################\n",
    "    # Convert to tokens logic #\n",
    "    ###########################\n",
    "    \n",
    "    # Advances to next character\n",
    "    def advance(self):\n",
    "        self.position += 1\n",
    "        self.current_char = self.text[self.position] if (self.position < self.text_length) else None\n",
    "    \n",
    "    def make_tokens(self):\n",
    "        tokens = []\n",
    "        \n",
    "        while (self.current_char != None):\n",
    "            if self.current_char == \" \":\n",
    "                self.advance()\n",
    "            elif self.current_char in DIGITS:\n",
    "                tokens.append(self._makeInteger())\n",
    "            elif self.current_char in ALPHABET:\n",
    "                tokens.append(self._makeFunc())\n",
    "            elif self.current_char == \"/\":\n",
    "                tokens.append(Token(TT_DIVIDE))\n",
    "                self.advance()\n",
    "            elif self.current_char == \"+\":\n",
    "                tokens.append(Token(TT_PLUS))\n",
    "                self.advance()\n",
    "            elif self.current_char == \"-\":\n",
    "                tokens.append(Token(TT_MINUS))\n",
    "                self.advance()\n",
    "            elif self.current_char == \"*\":\n",
    "                tokens.append(Token(TT_MULTIPLY))\n",
    "                self.advance()\n",
    "            elif self.current_char == \"(\":\n",
    "                tokens.append(Token(TT_LEFT_PARENTHESIS))\n",
    "                self.advance()\n",
    "            elif self.current_char == \")\":\n",
    "                tokens.append(Token(TT_RIGHT_PARENTHESIS))\n",
    "                self.advance()\n",
    "            elif self.current_char == \"!\":\n",
    "                tokens.append(Token(TT_FACTORIAL))\n",
    "                self.advance()\n",
    "            elif self.current_char in ALPHABET:\n",
    "                tokens.append(self._makeFunc())\n",
    "            else:\n",
    "                print(f\"ERROR unrecognised token: {self.current_char}\")\n",
    "                return []\n",
    "        \n",
    "        return tokens\n",
    "    \n",
    "    def _makeInteger(self):\n",
    "        res = \"\"\n",
    "        \n",
    "        while self.current_char and self.current_char in DIGITS:\n",
    "            res += self.current_char\n",
    "            self.advance()\n",
    "        \n",
    "        return Token(TT_INTEGER, int(res))\n",
    "    \n",
    "    def _makeFunc(self):\n",
    "        res = \"\"\n",
    "        \n",
    "        while self.current_char and self.current_char in ALPHABET:\n",
    "            res += self.current_char\n",
    "            self.advance()\n",
    "        \n",
    "        # Map to token type and return it\n",
    "        ## If: pi,e,phi,...\n",
    "        if res in SPECIAL_NUMBERS_DICT:\n",
    "            return SPECIAL_NUMBERS_DICT[res]\n",
    "        \n",
    "        ## If: x,y,z,m,n,...\n",
    "        elif len(res) == 1:\n",
    "            return Token(TT_VARIABLE, res)\n",
    "        \n",
    "        ## If: sqrt,sin,cos,...\n",
    "        elif res in UNI_OPERATORS:\n",
    "            return UNI_OPERATORS[res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b667a7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[---- Type: TT_INTEGER \t Value: 3 ----,\n",
       " ---- Type: TT_PLUS \t Value: None ----,\n",
       " ---- Type: TT_INTEGER \t Value: 18 ----,\n",
       " ---- Type: TT_DIVIDE \t Value: None ----,\n",
       " ---- Type: TT_LEFT_PARENTHESIS \t Value: None ----,\n",
       " ---- Type: TT_INTEGER \t Value: 9 ----,\n",
       " ---- Type: TT_MINUS \t Value: None ----,\n",
       " ---- Type: TT_INTEGER \t Value: 3 ----,\n",
       " ---- Type: TT_RIGHT_PARENTHESIS \t Value: None ----,\n",
       " ---- Type: TT_PLUS \t Value: None ----,\n",
       " ---- Type: TT_SIN \t Value: None ----,\n",
       " ---- Type: TT_LEFT_PARENTHESIS \t Value: None ----,\n",
       " ---- Type: TT_PI \t Value: None ----,\n",
       " ---- Type: TT_RIGHT_PARENTHESIS \t Value: None ----,\n",
       " ---- Type: TT_PLUS \t Value: None ----,\n",
       " ---- Type: TT_INTEGER \t Value: 2 ----]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equation = EquationLexer(\"3+18/(9-3)+sin(pi)+2\")\n",
    "equation.make_tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a51358",
   "metadata": {},
   "source": [
    "### Notation converter implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0458cf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Equation:\n",
    "    def __init__(self, tokenized_equation:list=None, notation:str=\"infix\"):\n",
    "        self.tokenized_equation = tokenized_equation\n",
    "        self.notation = notation\n",
    "        \n",
    "    def convertToInfix(self):\n",
    "        if self.notation == \"infix\":\n",
    "            return None\n",
    "        elif self.notation == \"postfix\":\n",
    "            token_list = list(reversed(self.tokenized_equation))\n",
    "            pass\n",
    "            \n",
    "    \n",
    "    def convertToPostfix(self):\n",
    "        if self.notation == \"infix\":\n",
    "            token_list = self.tokenized_equation\n",
    "            operator_stack = []\n",
    "            output_queue = []\n",
    "            #################\n",
    "            # Shunting yard #\n",
    "            #################\n",
    "            for token in token_list:\n",
    "                # Can be uncommented for debugging purposes\n",
    "                # print(\"#########\\n\", token, operator_stack, \"\\n########\")\n",
    "                \n",
    "                if token.t_type == TT_VARIABLE or token.t_type == TT_INTEGER or token.t_type == TT_RATIONAL:\n",
    "                    output_queue.append(token)\n",
    "                elif token.t_type in UNI_OPERATORS or token.t_type in BIN_OPERATORS:\n",
    "                    while operator_stack and self._operatorPrecedenceComparison(operator_stack[-1], token) in [0,1]:\n",
    "                        top_token = operator_stack.pop()\n",
    "                        output_queue.append(top_token)\n",
    "                    operator_stack.append(token)\n",
    "                elif token.t_type == TT_LEFT_PARENTHESIS:\n",
    "                    operator_stack.append(token)\n",
    "                elif token.t_type == TT_RIGHT_PARENTHESIS:\n",
    "                    top_token = operator_stack.pop()\n",
    "                    while operator_stack and top_token.t_type != TT_LEFT_PARENTHESIS:\n",
    "                        output_queue.append(top_token)\n",
    "                        top_token = operator_stack.pop()\n",
    "                else:\n",
    "                    print(f\"Error, unknown token: [{token}] --- could not convert equation\")\n",
    "                    return None\n",
    "            \n",
    "            while operator_stack:\n",
    "                top_token = operator_stack.pop()\n",
    "                output_queue.append(top_token)\n",
    "            \n",
    "            self.notation = \"postfix\"\n",
    "            self.tokenized_equation = output_queue\n",
    "                \n",
    "                \n",
    "    def convertToPrefix(self):\n",
    "        pass\n",
    "    \n",
    "    def _operatorPrecedenceComparison(self, operator_1: Token, operator_2: Token):\n",
    "        \"\"\"Compares operators in input for higher precedence\n",
    "        \n",
    "        Args:\n",
    "            operator_1 (Token)\n",
    "            operator_2 (Token)\n",
    "            \n",
    "        Returns:\n",
    "            -1 if either of operator_1 and operator_2 has no precedence or is not an operator\n",
    "            0 if operator_1 has higher precedence than operator_2\n",
    "            1 if operator_1 has equal precedence as operator_2\n",
    "            2 if operator_1 has less precedence than operator_2\n",
    "        \"\"\"\n",
    "        if not operator_1.t_type in OPERATOR_PRECEDENCE or not operator_2.t_type in OPERATOR_PRECEDENCE:\n",
    "            return -1\n",
    "        \n",
    "        # The logic\n",
    "        if OPERATOR_PRECEDENCE[operator_1.t_type] > OPERATOR_PRECEDENCE[operator_2.t_type]:\n",
    "            return 0\n",
    "        elif OPERATOR_PRECEDENCE[operator_1.t_type] == OPERATOR_PRECEDENCE[operator_2.t_type]:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "        \n",
    "        \n",
    "    @classmethod\n",
    "    def makeEquationFromString(cls, equation:str, notation=\"infix\"):\n",
    "        \"\"\"Makes equation instance from string\n",
    "        \n",
    "        Args:\n",
    "            equation (str): the equation to use in string format\n",
    "            notation (str): the notation used in the string equation\n",
    "        \n",
    "        Returns:\n",
    "            Instance of the Equation class initialized from equation\n",
    "        \"\"\"\n",
    "        lexer = EquationLexer(equation)\n",
    "        tokenized_equation = lexer.make_tokens()\n",
    "        return cls(tokenized_equation, notation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dd27489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[---- Type: TT_VARIABLE \t Value: n ----,\n",
       " ---- Type: TT_MULTIPLY \t Value: None ----,\n",
       " ---- Type: TT_INTEGER \t Value: 2 ----,\n",
       " ---- Type: TT_PLUS \t Value: None ----,\n",
       " ---- Type: TT_VARIABLE \t Value: a ----,\n",
       " ---- Type: TT_DIVIDE \t Value: None ----,\n",
       " ---- Type: TT_INTEGER \t Value: 3 ----]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equation = Equation.makeEquationFromString(\"n*2+a/3\")\n",
    "equation.tokenized_equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f8406f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[---- Type: TT_VARIABLE \t Value: n ----,\n",
       " ---- Type: TT_INTEGER \t Value: 2 ----,\n",
       " ---- Type: TT_MULTIPLY \t Value: None ----,\n",
       " ---- Type: TT_VARIABLE \t Value: a ----,\n",
       " ---- Type: TT_INTEGER \t Value: 3 ----,\n",
       " ---- Type: TT_DIVIDE \t Value: None ----,\n",
       " ---- Type: TT_PLUS \t Value: None ----]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equation.convertToPostfix()\n",
    "equation.tokenized_equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa854f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf818f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660926e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91176a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
