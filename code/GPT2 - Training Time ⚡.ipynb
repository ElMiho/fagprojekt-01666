{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "898d4440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# External imports\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "\n",
    "import datasets\n",
    "import transformers\n",
    "from transformers import AutoModel\n",
    "from datasets import load_dataset\n",
    "from accelerate import Accelerator\n",
    "\n",
    "from argparse import Namespace\n",
    "import logging\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "da2c1d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domestic imports\n",
    "from model.tokenize_input import input_string_to_tokenize_expression\n",
    "from model.tokens import TOKEN_TYPE_ANSWERS, TOKEN_TYPE_EXPRESSIONS\n",
    "from model.equation_interpreter import Equation\n",
    "from model.vocabulary import Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88a2e847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined vocabulary\n",
    "vocabulary = Vocabulary.construct_from_list(TOKEN_TYPE_EXPRESSIONS + TOKEN_TYPE_ANSWERS)\n",
    "vectorized_sample = vocabulary.vectorize([\"#\", \"/\", \"0\", \"-1\", \"[SEP]\", \"TT_INTEGER\"])\n",
    "vectorized_sample, [vocabulary.getToken(idx) for idx in vectorized_sample]\n",
    "\n",
    "# Global variables\n",
    "model_name = \"JustSumAI\"\n",
    "repo_name = f\"{model_name}_cleaned_gpt2_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8f3edf",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "54a6d515",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/metadata.txt\", \"r\") as f:\n",
    "    max_length = json.loads(f.read())[\"max_length\"]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f5023896",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"train_batch_size\": 8,\n",
    "    \"valid_batch_size\": 8,\n",
    "    \"weight_decay\": 0.1,\n",
    "    \"shuffle_buffer\": 1000,\n",
    "    \"learning_rate\": 2e-4,\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"num_warmup_steps\": 750,\n",
    "    \"gradient_accumulation_steps\": 16,\n",
    "    \"max_train_steps\": 50_000,\n",
    "    \"max_eval_steps\": -1,\n",
    "    \"seq_length\": max_length,\n",
    "    \"seed\": 628,\n",
    "    \"save_checkpoint_steps\": 50_000\n",
    "}\n",
    "args = Namespace(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaabf5b",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fab49f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = args.train_batch_size\n",
    "BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf18a07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/Hugo/.cache/huggingface/datasets/Dragonoverlord3000___parquet/Dragonoverlord3000--JustSumAI_cleaned_gpt2_data-7bb197e8e347c6a0/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc4595639c044cfbf37309409e457b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 336\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(f\"Dragonoverlord3000/{repo_name}\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3c5c345f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 9, 39, 25, 22, 21, 0, 4, 26, 23, 67, 51, 49, 49, 49, 61, 48, 59, 49, 61, 51, 49, 49, 61, 59, 48, 58, 49, 61, 58, 49, 48, 60, 49, 61, 58, 49, 44, 60, 49, 61, 58, 49, 49, 53, 60, 44, 60, 49, 61, 59, 49, 49, 49, 49, 61, 49, 53, 49, 61, 58, 61, 53, 60, 44, 60, 49, 61, 58, 49, 44, 60, 49, 49, 49, 61, 49, 53, 49, 61, 58, 53, 60, 61, 59, 49, 49, 57, 60, 49, 61, 59, 49, 49, 57, 60, 49, 61, 58, 49, 49, 57, 60, 49, 61, 59, 49, 49, 49, 53, 59, 49, 61, 57, 60, 49, 61, 59, 49, 49, 53, 60, 49, 49, 53, 59, 49, 61, 57, 60, 49, 61, 59, 49, 49, 49, 53, 58, 49, 61, 57, 60, 49, 61, 59, 49, 49, 53, 60, 49, 49, 53, 58, 49, 61, 57, 60, 49, 61, 58, 60, 59, 65]\n"
     ]
    }
   ],
   "source": [
    "print(json.loads(dataset[\"train\"][0][\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "300ade79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x207fbd44520>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(dataset[\"train\"], shuffle=True, batch_size=BATCH_SIZE)\n",
    "train_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004d58a2",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f071870b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a098be61a8d47a2b268966149c4134b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/931 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62cc32c5db7243129701c32a5b2c82b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/5.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Dragonoverlord3000/JustSumAI were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(68, 1600)\n",
       "  (wpe): Embedding(1024, 1600)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-47): 48 x GPT2Block(\n",
       "      (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(f\"Dragonoverlord3000/{model_name}\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6dd2fb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GPT-2 Number of parameters: 1477.31M'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"GPT-2 Number of parameters: {model.num_parameters()/1_000_000:.2f}M\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171a161b",
   "metadata": {},
   "source": [
    "### Define weight decay parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "afb85cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grouped_params(model, no_decay=[\"bias\", \"LayerNorm.weight\"]):\n",
    "    params_with_wd, params_without_wd = [], []\n",
    "    for n,p in model.named_parameters():\n",
    "        if any(nd in n for nd in no_decay):\n",
    "            params_without_wd.append(p)\n",
    "        else:\n",
    "            params_with_wd.append(p)\n",
    "            \n",
    "        return [{\"params\": params_with_wd, \"weight_decay\": args.weight_decay},\n",
    "               {\"params\": params_without_wd, \"weight_decay\": 0.0}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b71c05",
   "metadata": {},
   "source": [
    "### Setting up the accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "27c48004",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aad138",
   "metadata": {},
   "source": [
    "### Setting up logging for the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6c754006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logging(project_name=\"JustSumAI\"):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname) - %(name)s - %(message)s\",\n",
    "        datefmt=\"%m/%d/&Y %H:%M:%S\", level=logging.INFO, handlers=[\n",
    "            logging.FileHandler(f\"log/debug_{accelerator.process_index}.log\"),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Make sure only main thread activates logging\n",
    "    if accelerator.is_main_process:\n",
    "        logger.setLevel(logging.INFO)\n",
    "        datasets.utils.logging.set_verbosity_debug()\n",
    "        transformers.utils.logging.set_verbosity_info()\n",
    "    else:\n",
    "        logger.setLevel(logging.ERROR)\n",
    "        datasets.utils.logging.set_verbosity_error()\n",
    "        transformers.utils.logging.set_verbosity_error()\n",
    "        \n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37b6b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for step,batch in enumerate(eval_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5684c46",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d499fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e7ac7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bd04f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ab614a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776a656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a063718f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42824c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e2236a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86028c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691ada24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
